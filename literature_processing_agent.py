#!/usr/bin/env python3
"""
å…¨æµç¨‹æ–‡çŒ®å¤„ç†Agent
æ”¯æŒæ ¹æ®ç”¨æˆ·è¾“å…¥çš„éœ€æ±‚ï¼Œè‡ªåŠ¨è°ƒç”¨MinerUè§£æPDFï¼ŒåŠ¨æ€ç”Ÿæˆæç¤ºè¯æå–ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆæ€ç»´å¯¼å›¾

åŠŸèƒ½åŒ…æ‹¬ï¼š
1. è°ƒç”¨MinerU APIè§£æPDFæ–‡çŒ®
2. æ ¹æ®ç”¨æˆ·éœ€æ±‚åŠ¨æ€ç”Ÿæˆæç¤ºè¯
3. è°ƒç”¨O3 APIæå–æ‰€éœ€ä¿¡æ¯
4. ç”Ÿæˆæ–‡çŒ®æ€ç»´å¯¼å›¾
5. æ”¯æŒå•ä¸ªPDFå’Œæ‰¹é‡å¤„ç†

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025å¹´1æœˆ
"""

import os
import json
import time
import requests
from pathlib import Path
from datetime import datetime
from openai import OpenAI

# å¯¼å…¥ç°æœ‰æ¨¡å—
from mineru_pdf_parser import MinerUParser
import full_structure_property_extraction as extractor
from config import Config

class LiteratureProcessingAgent:
    """å…¨æµç¨‹æ–‡çŒ®å¤„ç†Agent"""
    
    def __init__(self, config_file="config.json"):
        """åˆå§‹åŒ–Agent"""
        # åŠ è½½é…ç½®
        self.config = Config(config_file)
        
        # æ£€æŸ¥å¿…è¦çš„APIå¯†é’¥
        missing_keys = self.config.get_missing_keys()
        if missing_keys:
            print("âš ï¸  ç¼ºå¤±APIå¯†é’¥é…ç½®:")
            for key in missing_keys:
                print(f"   - {key}")
            print("\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡Œé…ç½®:")
            print("   python config.py setup")
            print("æˆ–æ‰‹åŠ¨ç¼–è¾‘ config.json æ–‡ä»¶")
        
        self.mineru_parser = MinerUParser()
        
        # O3 APIé…ç½®
        self.o3_api_key = self.config.get('o3_api_key')
        if not self.o3_api_key:
            raise ValueError("O3 APIå¯†é’¥æœªé…ç½®ï¼Œè¯·è¿è¡Œ 'python config.py setup' è¿›è¡Œé…ç½®")
        
        self.o3_client = OpenAI(
            api_key=self.o3_api_key,
            base_url=self.config.get('o3_base_url', 'https://api.o3.fan/v1')
        )
        self.o3_model = self.config.get('o3_model', 'claude-sonnet-4-20250514')
        
        # æ€ç»´å¯¼å›¾APIé…ç½®ï¼ˆä½¿ç”¨Whimsicalæˆ–å…¶ä»–æ€ç»´å¯¼å›¾æœåŠ¡ï¼‰
        self.mindmap_api_base = "https://whimsical.com/api/v1"
        
    def call_o3(self, prompt, temperature=0.2, retries=3):
        """è°ƒç”¨O3 API"""
        for attempt in range(retries):
            try:
                response = self.o3_client.chat.completions.create(
                    model=self.o3_model,
                    messages=[
                        {"role": "system", "content": "You are a precise extractor for academic literature and an expert assistant."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=temperature
                )
                return response.choices[0].message.content
            except Exception as e:
                print(f"[Retry {attempt+1}] O3 API call failed: {e}")
                if attempt < retries - 1:
                    time.sleep(5)
        return ""
    
    def generate_dynamic_prompts(self, user_requirements):
        """æ ¹æ®ç”¨æˆ·éœ€æ±‚åŠ¨æ€ç”Ÿæˆæç¤ºè¯"""
        prompt_generator = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æç¤ºè¯å·¥ç¨‹å¸ˆï¼Œéœ€è¦æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ç”Ÿæˆç”¨äºæ–‡çŒ®ä¿¡æ¯æå–çš„æç¤ºè¯ã€‚

ç”¨æˆ·éœ€æ±‚ï¼š
{user_requirements}

è¯·ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„JSONæ ¼å¼æç¤ºè¯æ¨¡æ¿ï¼Œç”¨äºä»å­¦æœ¯æ–‡çŒ®ä¸­æå–ç”¨æˆ·æ‰€éœ€çš„ä¿¡æ¯ã€‚

è¦æ±‚ï¼š
1. æç¤ºè¯åº”è¯¥æ¸…æ™°ã€å…·ä½“ã€ç»“æ„åŒ–
2. è¿”å›çš„JSONç»“æ„åº”è¯¥åŒ…å«ç”¨æˆ·å…³å¿ƒçš„æ‰€æœ‰ä¿¡æ¯å­—æ®µ
3. è€ƒè™‘ä¸åŒç±»å‹çš„æ–‡çŒ®ï¼ˆç ”ç©¶è®ºæ–‡ã€ç»¼è¿°ç­‰ï¼‰
4. åŒ…å«é€‚å½“çš„æ•°æ®éªŒè¯å’Œæ ¼å¼è¦æ±‚
5. æç¤ºè¯åº”è¯¥æŒ‡å¯¼AIæå–å‡†ç¡®ã€å®Œæ•´çš„ä¿¡æ¯

è¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„æç¤ºè¯æ¨¡æ¿ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "extraction_prompt": "è¯¦ç»†çš„æå–æŒ‡ä»¤...",
  "target_json_structure": {{
    // ç›®æ ‡JSONç»“æ„
  }},
  "validation_criteria": [
    "éªŒè¯æ ‡å‡†1",
    "éªŒè¯æ ‡å‡†2"
  ],
  "special_instructions": [
    "ç‰¹æ®ŠæŒ‡ä»¤1",
    "ç‰¹æ®ŠæŒ‡ä»¤2"
  ]
}}

åªè¿”å›JSONæ ¼å¼çš„ç»“æœï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
"""
        
        response = self.call_o3(prompt_generator, temperature=0.3)
        
        try:
            # æ¸…ç†å“åº”ï¼Œæå–JSON
            if "```json" in response:
                response = response.split("```json")[1].split("```")[0].strip()
            elif "```" in response:
                response = response.split("```")[1].strip()
            
            return json.loads(response)
        except json.JSONDecodeError as e:
            print(f"âŒ ç”Ÿæˆæç¤ºè¯å¤±è´¥: {e}")
            return None
    
    def extract_information_with_dynamic_prompt(self, content, dynamic_prompts, images=None):
        """ä½¿ç”¨åŠ¨æ€ç”Ÿæˆçš„æç¤ºè¯æå–ä¿¡æ¯"""
        if not dynamic_prompts:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æç¤ºè¯æ¨¡æ¿")
            return None
        
        extraction_prompt = dynamic_prompts.get("extraction_prompt", "")
        target_structure = dynamic_prompts.get("target_json_structure", {})
        
        # æ„å»ºå®Œæ•´çš„æå–æç¤ºè¯
        full_prompt = f"""
{extraction_prompt}

ç›®æ ‡JSONç»“æ„ï¼š
{json.dumps(target_structure, indent=2, ensure_ascii=False)}

æ–‡çŒ®å†…å®¹ï¼š
\"\"\"{content}\"\"\"

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°JSONç»“æ„æå–ä¿¡æ¯ã€‚å¦‚æœæŸä¸ªå­—æ®µåœ¨æ–‡çŒ®ä¸­æ²¡æœ‰æåŠï¼Œè¯·ä½¿ç”¨"N/A"ä½œä¸ºå€¼ã€‚
åªè¿”å›JSONæ ¼å¼çš„ç»“æœï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
"""
        
        # è°ƒç”¨O3 APIè¿›è¡Œä¿¡æ¯æå–
        if images:
            # å¦‚æœæœ‰å›¾ç‰‡ï¼Œä½¿ç”¨å›¾ç‰‡å¢å¼ºçš„æå–
            return self.extract_with_images(full_prompt, images)
        else:
            # çº¯æ–‡æœ¬æå–
            raw = self.call_o3(full_prompt)
            
            # æ¸…ç†å“åº”
            if "```json" in raw:
                raw = raw.split("```json")[1].split("```")[0].strip()
            elif "```" in raw:
                raw = raw.split("```")[1].strip()
            
            try:
                return json.loads(raw)
            except json.JSONDecodeError:
                print("âŒ è§£ææå–ç»“æœå¤±è´¥")
                return None
    
    def extract_with_images(self, prompt, image_paths):
        """ç»“åˆå›¾ç‰‡è¿›è¡Œä¿¡æ¯æå–"""
        # ç¼–ç å›¾ç‰‡ï¼ˆé™åˆ¶æ•°é‡ï¼‰
        selected_images = image_paths[:5]  # æœ€å¤š5å¼ å›¾ç‰‡
        image_base64_list = []
        
        for img_path in selected_images:
            base64_data = extractor.encode_image_to_base64(img_path)
            if base64_data:
                image_base64_list.append(base64_data)
        
        if not image_base64_list:
            return self.call_o3(prompt)
        
        try:
            messages = [
                {"role": "system", "content": "You are a precise extractor for academic literature with image analysis capabilities."},
                {"role": "user", "content": [
                    {"type": "text", "text": prompt}
                ] + [
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{img_base64}"}
                    }
                    for img_base64 in image_base64_list
                ]}
            ]
            
            response = self.o3_client.chat.completions.create(
                model=self.o3_model,
                messages=messages,
                temperature=0.2
            )
            
            raw = response.choices[0].message.content
            
            # æ¸…ç†å“åº”
            if "```json" in raw:
                raw = raw.split("```json")[1].split("```")[0].strip()
            elif "```" in raw:
                raw = raw.split("```")[1].strip()
            
            try:
                return json.loads(raw)
            except json.JSONDecodeError:
                print("âŒ è§£æå›¾ç‰‡å¢å¼ºæå–ç»“æœå¤±è´¥")
                return None
                
        except Exception as e:
            print(f"âŒ å›¾ç‰‡å¢å¼ºæå–å¤±è´¥: {e}")
            return None
    
    def generate_mindmap(self, literature_data, title="æ–‡çŒ®æ€ç»´å¯¼å›¾"):
        """ç”Ÿæˆæ–‡çŒ®æ€ç»´å¯¼å›¾"""
        # å‡†å¤‡æ€ç»´å¯¼å›¾æ•°æ®
        mindmap_prompt = f"""
åŸºäºä»¥ä¸‹æ–‡çŒ®æå–çš„ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„æ€ç»´å¯¼å›¾æ•°æ®ï¼š

æ–‡çŒ®æ•°æ®ï¼š
{json.dumps(literature_data, indent=2, ensure_ascii=False)}

è¯·ç”Ÿæˆä¸€ä¸ªæ€ç»´å¯¼å›¾çš„JSONç»“æ„ï¼ŒåŒ…å«ä»¥ä¸‹è¦ç´ ï¼š
1. ä¸­å¿ƒä¸»é¢˜ï¼ˆæ–‡çŒ®æ ‡é¢˜æˆ–ä¸»è¦ç ”ç©¶å†…å®¹ï¼‰
2. ä¸»è¦åˆ†æ”¯ï¼ˆç ”ç©¶æ–¹æ³•ã€å…³é”®å‘ç°ã€åº”ç”¨ç­‰ï¼‰
3. å­åˆ†æ”¯ï¼ˆå…·ä½“ç»†èŠ‚ï¼‰
4. é¢œè‰²å’Œæ ·å¼å»ºè®®

è¾“å‡ºæ ¼å¼ï¼š
{{
  "central_topic": "ä¸­å¿ƒä¸»é¢˜",
  "branches": [
    {{
      "name": "åˆ†æ”¯åç§°",
      "color": "#é¢œè‰²ä»£ç ",
      "children": [
        {{
          "name": "å­åˆ†æ”¯åç§°",
          "details": ["è¯¦ç»†ä¿¡æ¯1", "è¯¦ç»†ä¿¡æ¯2"]
        }}
      ]
    }}
  ],
  "summary": "æ€ç»´å¯¼å›¾æ€»ç»“"
}}

åªè¿”å›JSONæ ¼å¼çš„ç»“æœã€‚
"""
        
        mindmap_data = self.call_o3(mindmap_prompt, temperature=0.3)
        
        try:
            if "```json" in mindmap_data:
                mindmap_data = mindmap_data.split("```json")[1].split("```")[0].strip()
            elif "```" in mindmap_data:
                mindmap_data = mindmap_data.split("```")[1].strip()
            
            mindmap_json = json.loads(mindmap_data)
            
            # ç”Ÿæˆæ€ç»´å¯¼å›¾çš„å¯è§†åŒ–ä»£ç ï¼ˆä½¿ç”¨Mermaidæ ¼å¼ï¼‰
            mermaid_code = self.convert_to_mermaid(mindmap_json)
            
            return {
                "mindmap_data": mindmap_json,
                "mermaid_code": mermaid_code
            }
            
        except json.JSONDecodeError as e:
            print(f"âŒ ç”Ÿæˆæ€ç»´å¯¼å›¾å¤±è´¥: {e}")
            return None
    
    def convert_to_mermaid(self, mindmap_data):
        """å°†æ€ç»´å¯¼å›¾æ•°æ®è½¬æ¢ä¸ºMermaidæ ¼å¼"""
        mermaid_lines = ["mindmap"]
        mermaid_lines.append(f"  root(({mindmap_data.get('central_topic', 'æ–‡çŒ®åˆ†æ')}))")
        
        for i, branch in enumerate(mindmap_data.get('branches', [])):
            branch_name = branch.get('name', f'åˆ†æ”¯{i+1}')
            mermaid_lines.append(f"    {branch_name}")
            
            for j, child in enumerate(branch.get('children', [])):
                child_name = child.get('name', f'å­åˆ†æ”¯{j+1}')
                mermaid_lines.append(f"      {child_name}")
                
                for detail in child.get('details', []):
                    if len(detail) < 20:  # åªæ˜¾ç¤ºçŸ­çš„è¯¦ç»†ä¿¡æ¯
                        mermaid_lines.append(f"        {detail}")
        
        return "\n".join(mermaid_lines)
    
    def process_single_pdf(self, pdf_path, user_requirements, output_dir="processed_results"):
        """å¤„ç†å•ä¸ªPDFæ–‡ä»¶çš„å®Œæ•´æµç¨‹"""
        print(f"ğŸš€ å¼€å§‹å¤„ç†PDFæ–‡ä»¶: {os.path.basename(pdf_path)}")
        print("=" * 80)
        
        # æ­¥éª¤1: ä½¿ç”¨MinerUè§£æPDF
        print("ğŸ“„ æ­¥éª¤1: è§£æPDFæ–‡ä»¶...")
        parsed_result = self.mineru_parser.parse_single_pdf(pdf_path)
        
        if not parsed_result:
            print("âŒ PDFè§£æå¤±è´¥")
            return None
        
        # ä¸‹è½½è§£æç»“æœ
        print("ğŸ“¥ ä¸‹è½½è§£æç»“æœ...")
        extract_dir = self.mineru_parser.download_result(parsed_result, output_dir)
        
        if not extract_dir:
            print("âŒ ä¸‹è½½è§£æç»“æœå¤±è´¥")
            return None
        
        # æ­¥éª¤2: æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆæç¤ºè¯
        print("\nğŸ§  æ­¥éª¤2: æ ¹æ®éœ€æ±‚ç”Ÿæˆæå–æç¤ºè¯...")
        dynamic_prompts = self.generate_dynamic_prompts(user_requirements)
        
        if not dynamic_prompts:
            print("âŒ ç”Ÿæˆæç¤ºè¯å¤±è´¥")
            return None
        
        print("âœ… æç¤ºè¯ç”ŸæˆæˆåŠŸ")
        
        # æ­¥éª¤3: è¯»å–è§£æåçš„å†…å®¹
        print("\nğŸ“– æ­¥éª¤3: è¯»å–æ–‡æ¡£å†…å®¹...")
        md_file = os.path.join(extract_dir, "full.md")
        
        if not os.path.exists(md_file):
            print("âŒ æ‰¾ä¸åˆ°è§£æåçš„markdownæ–‡ä»¶")
            return None
        
        with open(md_file, "r", encoding="utf-8") as f:
            content = f.read()
        
        # æŸ¥æ‰¾å›¾ç‰‡
        images_dir = os.path.join(extract_dir, "images")
        image_paths = []
        if os.path.exists(images_dir):
            for img_file in os.listdir(images_dir):
                if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                    image_paths.append(os.path.join(images_dir, img_file))
        
        print(f"ğŸ“„ æ–‡æ¡£é•¿åº¦: {len(content)} å­—ç¬¦")
        print(f"ğŸ–¼ï¸ æ‰¾åˆ°å›¾ç‰‡: {len(image_paths)} å¼ ")
        
        # æ­¥éª¤4: æå–ä¿¡æ¯
        print("\nğŸ” æ­¥éª¤4: æå–æ–‡çŒ®ä¿¡æ¯...")
        extracted_info = self.extract_information_with_dynamic_prompt(
            content, dynamic_prompts, image_paths
        )
        
        if not extracted_info:
            print("âŒ ä¿¡æ¯æå–å¤±è´¥")
            return None
        
        print("âœ… ä¿¡æ¯æå–æˆåŠŸ")
        
        # æ­¥éª¤5: ç”Ÿæˆæ€ç»´å¯¼å›¾
        print("\nğŸ§  æ­¥éª¤5: ç”Ÿæˆæ€ç»´å¯¼å›¾...")
        mindmap_result = self.generate_mindmap(extracted_info, os.path.basename(pdf_path))
        
        if not mindmap_result:
            print("âŒ æ€ç»´å¯¼å›¾ç”Ÿæˆå¤±è´¥")
            mindmap_result = {"mindmap_data": None, "mermaid_code": None}
        else:
            print("âœ… æ€ç»´å¯¼å›¾ç”ŸæˆæˆåŠŸ")
        
        # æ­¥éª¤6: ä¿å­˜ç»“æœ
        print("\nğŸ’¾ æ­¥éª¤6: ä¿å­˜å¤„ç†ç»“æœ...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_filename = "".join(c for c in os.path.basename(pdf_path) if c.isalnum() or c in (' ', '-', '_', '.')).strip()
        result_dir = os.path.join(output_dir, f"{safe_filename}_{timestamp}")
        os.makedirs(result_dir, exist_ok=True)
        
        # ä¿å­˜æå–çš„ä¿¡æ¯
        info_file = os.path.join(result_dir, "extracted_information.json")
        with open(info_file, "w", encoding="utf-8") as f:
            json.dump({
                "processing_info": {
                    "pdf_file": pdf_path,
                    "user_requirements": user_requirements,
                    "processing_time": datetime.now().isoformat(),
                    "dynamic_prompts": dynamic_prompts
                },
                "extracted_data": extracted_info
            }, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜æ€ç»´å¯¼å›¾
        if mindmap_result["mindmap_data"]:
            mindmap_file = os.path.join(result_dir, "mindmap.json")
            with open(mindmap_file, "w", encoding="utf-8") as f:
                json.dump(mindmap_result["mindmap_data"], f, ensure_ascii=False, indent=2)
        
        if mindmap_result["mermaid_code"]:
            mermaid_file = os.path.join(result_dir, "mindmap.mmd")
            with open(mermaid_file, "w", encoding="utf-8") as f:
                f.write(mindmap_result["mermaid_code"])
        
        # åˆ›å»ºå¤„ç†æŠ¥å‘Š
        report_file = os.path.join(result_dir, "processing_report.md")
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(f"""# æ–‡çŒ®å¤„ç†æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **PDFæ–‡ä»¶**: {os.path.basename(pdf_path)}
- **å¤„ç†æ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- **ç”¨æˆ·éœ€æ±‚**: {user_requirements}

## å¤„ç†ç»“æœ
- **åŸå§‹PDFè§£æ**: {'âœ…' if parsed_result else 'âŒ'}
- **ä¿¡æ¯æå–**: {'âœ…' if extracted_info else 'âŒ'}
- **æ€ç»´å¯¼å›¾ç”Ÿæˆ**: {'âœ…' if mindmap_result["mindmap_data"] else 'âŒ'}

## è¾“å‡ºæ–‡ä»¶
- `extracted_information.json`: æå–çš„ç»“æ„åŒ–ä¿¡æ¯
- `mindmap.json`: æ€ç»´å¯¼å›¾æ•°æ®
- `mindmap.mmd`: Mermaidæ ¼å¼æ€ç»´å¯¼å›¾ä»£ç 

## æå–åˆ°çš„ä¿¡æ¯æ¦‚è§ˆ
{json.dumps(extracted_info, ensure_ascii=False, indent=2)[:500]}...

## æ€ç»´å¯¼å›¾é¢„è§ˆ
```mermaid
{mindmap_result["mermaid_code"] or "æ€ç»´å¯¼å›¾ç”Ÿæˆå¤±è´¥"}
```
""")
        
        print(f"âœ… å¤„ç†å®Œæˆ! ç»“æœä¿å­˜åœ¨: {result_dir}")
        
        return {
            "result_dir": result_dir,
            "extracted_info": extracted_info,
            "mindmap_data": mindmap_result["mindmap_data"],
            "mermaid_code": mindmap_result["mermaid_code"],
            "dynamic_prompts": dynamic_prompts
        }
    
    def process_batch_pdfs(self, pdf_files, user_requirements, output_dir="batch_processed_results"):
        """æ‰¹é‡å¤„ç†PDFæ–‡ä»¶"""
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
        print("=" * 80)
        
        # æ­¥éª¤1: æ‰¹é‡è§£æPDF
        print("ğŸ“„ æ­¥éª¤1: æ‰¹é‡è§£æPDFæ–‡ä»¶...")
        parsed_results = self.mineru_parser.parse_batch_pdfs(pdf_files)
        
        if not parsed_results:
            print("âŒ æ‰¹é‡PDFè§£æå¤±è´¥")
            return None
        
        # ä¸‹è½½æ‰¹é‡è§£æç»“æœ
        print("ğŸ“¥ ä¸‹è½½æ‰¹é‡è§£æç»“æœ...")
        downloaded_dirs = self.mineru_parser.download_batch_results(parsed_results, output_dir)
        
        if not downloaded_dirs:
            print("âŒ ä¸‹è½½æ‰¹é‡è§£æç»“æœå¤±è´¥")
            return None
        
        # æ­¥éª¤2: æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆæç¤ºè¯ï¼ˆåªç”Ÿæˆä¸€æ¬¡ï¼‰
        print("\nğŸ§  æ­¥éª¤2: æ ¹æ®éœ€æ±‚ç”Ÿæˆæå–æç¤ºè¯...")
        dynamic_prompts = self.generate_dynamic_prompts(user_requirements)
        
        if not dynamic_prompts:
            print("âŒ ç”Ÿæˆæç¤ºè¯å¤±è´¥")
            return None
        
        print("âœ… æç¤ºè¯ç”ŸæˆæˆåŠŸ")
        
        # æ­¥éª¤3: å¤„ç†æ¯ä¸ªè§£æåçš„æ–‡ä»¶
        all_results = []
        
        for i, extract_dir in enumerate(downloaded_dirs, 1):
            print(f"\nğŸ“– å¤„ç†æ–‡ä»¶ {i}/{len(downloaded_dirs)}: {os.path.basename(extract_dir)}")
            
            try:
                # è¯»å–å†…å®¹
                md_file = os.path.join(extract_dir, "full.md")
                if not os.path.exists(md_file):
                    print(f"âš ï¸ è·³è¿‡: æ‰¾ä¸åˆ°markdownæ–‡ä»¶")
                    continue
                
                with open(md_file, "r", encoding="utf-8") as f:
                    content = f.read()
                
                # æŸ¥æ‰¾å›¾ç‰‡
                images_dir = os.path.join(extract_dir, "images")
                image_paths = []
                if os.path.exists(images_dir):
                    for img_file in os.listdir(images_dir):
                        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                            image_paths.append(os.path.join(images_dir, img_file))
                
                # æå–ä¿¡æ¯
                print(f"  ğŸ” æå–ä¿¡æ¯...")
                extracted_info = self.extract_information_with_dynamic_prompt(
                    content, dynamic_prompts, image_paths
                )
                
                if not extracted_info:
                    print(f"  âŒ ä¿¡æ¯æå–å¤±è´¥")
                    continue
                
                # ç”Ÿæˆæ€ç»´å¯¼å›¾
                print(f"  ğŸ§  ç”Ÿæˆæ€ç»´å¯¼å›¾...")
                mindmap_result = self.generate_mindmap(extracted_info, os.path.basename(extract_dir))
                
                # ä¿å­˜å•ä¸ªæ–‡ä»¶çš„ç»“æœ
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                result_file = os.path.join(extract_dir, f"processing_result_{timestamp}.json")
                
                result_data = {
                    "processing_info": {
                        "extract_dir": extract_dir,
                        "user_requirements": user_requirements,
                        "processing_time": datetime.now().isoformat(),
                        "batch_index": i,
                        "dynamic_prompts": dynamic_prompts
                    },
                    "extracted_data": extracted_info,
                    "mindmap_data": mindmap_result["mindmap_data"] if mindmap_result else None,
                    "mermaid_code": mindmap_result["mermaid_code"] if mindmap_result else None
                }
                
                with open(result_file, "w", encoding="utf-8") as f:
                    json.dump(result_data, f, ensure_ascii=False, indent=2)
                
                all_results.append(result_data)
                print(f"  âœ… å¤„ç†å®Œæˆ")
                
                # æ¯å¤„ç†5ä¸ªæ–‡ä»¶ä¼‘æ¯ä¸€ä¸‹
                if i % 5 == 0:
                    print(f"  â¸ï¸ å·²å¤„ç† {i} ä¸ªæ–‡ä»¶ï¼Œä¼‘æ¯ç‰‡åˆ»...")
                    time.sleep(10)
                    
            except Exception as e:
                print(f"  âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                continue
        
        # æ­¥éª¤4: ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š
        print(f"\nğŸ“Š ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        batch_report_dir = os.path.join(output_dir, f"batch_report_{timestamp}")
        os.makedirs(batch_report_dir, exist_ok=True)
        
        # ä¿å­˜æ‰¹é‡ç»“æœ
        batch_results_file = os.path.join(batch_report_dir, "batch_results.json")
        with open(batch_results_file, "w", encoding="utf-8") as f:
            json.dump({
                "batch_info": {
                    "total_files": len(pdf_files),
                    "successfully_processed": len(all_results),
                    "user_requirements": user_requirements,
                    "processing_time": datetime.now().isoformat(),
                    "dynamic_prompts": dynamic_prompts
                },
                "results": all_results
            }, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆæ‰¹é‡æŠ¥å‘Š
        report_file = os.path.join(batch_report_dir, "batch_report.md")
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(f"""# æ‰¹é‡æ–‡çŒ®å¤„ç†æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **å¤„ç†æ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- **ç”¨æˆ·éœ€æ±‚**: {user_requirements}
- **æ€»æ–‡ä»¶æ•°**: {len(pdf_files)}
- **æˆåŠŸå¤„ç†**: {len(all_results)}

## å¤„ç†ç»“æœæ¦‚è§ˆ
""")
            
            for i, result in enumerate(all_results, 1):
                extract_dir = result["processing_info"]["extract_dir"]
                f.write(f"\n### {i}. {os.path.basename(extract_dir)}\n")
                f.write(f"- **çŠ¶æ€**: {'âœ…' if result['extracted_data'] else 'âŒ'}\n")
                f.write(f"- **æ€ç»´å¯¼å›¾**: {'âœ…' if result['mindmap_data'] else 'âŒ'}\n")
                
                # ç®€è¦å±•ç¤ºæå–çš„ä¿¡æ¯
                if result['extracted_data']:
                    data_str = json.dumps(result['extracted_data'], ensure_ascii=False, indent=2)
                    f.write(f"- **æå–ä¿¡æ¯é¢„è§ˆ**: {data_str[:200]}...\n")
        
        print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ! å¤„ç†äº† {len(all_results)}/{len(pdf_files)} ä¸ªæ–‡ä»¶")
        print(f"ğŸ“Š æ‰¹é‡æŠ¥å‘Šä¿å­˜åœ¨: {batch_report_dir}")
        
        return {
            "batch_report_dir": batch_report_dir,
            "total_processed": len(all_results),
            "total_files": len(pdf_files),
            "results": all_results,
            "dynamic_prompts": dynamic_prompts
        }


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œç•Œé¢"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å…¨æµç¨‹æ–‡çŒ®å¤„ç†Agent")
    parser.add_argument("mode", choices=["single", "batch"], help="å¤„ç†æ¨¡å¼")
    parser.add_argument("--pdf", help="å•ä¸ªPDFæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--dir", help="åŒ…å«PDFæ–‡ä»¶çš„ç›®å½•ï¼ˆæ‰¹é‡å¤„ç†ï¼‰")
    parser.add_argument("--requirements", help="ç”¨æˆ·éœ€æ±‚æè¿°")
    parser.add_argument("--output", default="agent_results", help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–Agent
    agent = LiteratureProcessingAgent()
    
    # è·å–ç”¨æˆ·éœ€æ±‚
    requirements = args.requirements
    if not requirements:
        print("è¯·æè¿°æ‚¨æƒ³ä»æ–‡çŒ®ä¸­æå–çš„ä¿¡æ¯ï¼š")
        requirements = input("> ")
    
    if args.mode == "single":
        # å•ä¸ªæ–‡ä»¶å¤„ç†
        pdf_file = args.pdf
        if not pdf_file:
            # æŸ¥æ‰¾å½“å‰ç›®å½•çš„PDFæ–‡ä»¶
            pdf_files = list(Path('.').glob('*.pdf'))
            if not pdf_files:
                print("âŒ æœªæ‰¾åˆ°PDFæ–‡ä»¶")
                return
            elif len(pdf_files) == 1:
                pdf_file = str(pdf_files[0])
            else:
                print("å‘ç°å¤šä¸ªPDFæ–‡ä»¶ï¼Œè¯·é€‰æ‹©ï¼š")
                for i, pdf in enumerate(pdf_files, 1):
                    print(f"  {i}. {pdf.name}")
                try:
                    choice = int(input("è¯·é€‰æ‹© (1-{}): ".format(len(pdf_files)))) - 1
                    pdf_file = str(pdf_files[choice])
                except (ValueError, IndexError):
                    print("âŒ æ— æ•ˆé€‰æ‹©")
                    return
        
        # å¤„ç†å•ä¸ªPDF
        result = agent.process_single_pdf(pdf_file, requirements, args.output)
        
        if result:
            print(f"\nğŸ‰ å¤„ç†æˆåŠŸ!")
            print(f"ğŸ“ ç»“æœç›®å½•: {result['result_dir']}")
        else:
            print("\nâŒ å¤„ç†å¤±è´¥")
    
    elif args.mode == "batch":
        # æ‰¹é‡å¤„ç†
        pdf_dir = args.dir or "."
        pdf_files = list(Path(pdf_dir).glob('*.pdf'))
        
        if not pdf_files:
            print(f"âŒ åœ¨ {pdf_dir} ç›®å½•ä¸­æœªæ‰¾åˆ°PDFæ–‡ä»¶")
            return
        
        print(f"å‘ç° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
        confirm = input("ç¡®è®¤æ‰¹é‡å¤„ç†? (y/N): ").strip().lower()
        if confirm != 'y':
            print("âŒ ç”¨æˆ·å–æ¶ˆ")
            return
        
        # æ‰¹é‡å¤„ç†
        result = agent.process_batch_pdfs([str(f) for f in pdf_files], requirements, args.output)
        
        if result:
            print(f"\nğŸ‰ æ‰¹é‡å¤„ç†æˆåŠŸ!")
            print(f"ğŸ“ æŠ¥å‘Šç›®å½•: {result['batch_report_dir']}")
            print(f"ğŸ“Š æˆåŠŸå¤„ç†: {result['total_processed']}/{result['total_files']} ä¸ªæ–‡ä»¶")
        else:
            print("\nâŒ æ‰¹é‡å¤„ç†å¤±è´¥")


if __name__ == "__main__":
    main()