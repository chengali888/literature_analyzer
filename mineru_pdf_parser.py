#!/usr/bin/env python3
"""
MinerU PDFè§£æå·¥å…·
æ”¯æŒå•ä¸ªPDFæ–‡ä»¶å’Œæ‰¹é‡PDFæ–‡ä»¶è§£æ
ä¸¥æ ¼æŒ‰ç…§MinerU APIæ–‡æ¡£å®ç°

ä½¿ç”¨æ–¹æ³•:
1. å•ä¸ªPDFè§£æ: python mineru_pdf_parser.py single
2. æ‰¹é‡PDFè§£æ: python mineru_pdf_parser.py batch
3. è‡ªåŠ¨æ¨¡å¼: python mineru_pdf_parser.py (è‡ªåŠ¨æ£€æµ‹å½“å‰ç›®å½•PDFæ–‡ä»¶)

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025å¹´1æœˆ
"""

import requests
import json
import time
import os
import zipfile
import sys
from pathlib import Path

# APIé…ç½®
API_TOKEN = "eyJ0eXBlIjoiSldUIiwiYWxnIjoiSFM1MTIifQ.eyJqdGkiOiI5MTkwNDMwNSIsInJvbCI6IlJPTEVfUkVHSVNURVIiLCJpc3MiOiJPcGVuWExhYiIsImlhdCI6MTc1NDMwNzc1MiwiY2xpZW50SWQiOiJsa3pkeDU3bnZ5MjJqa3BxOXgydyIsInBob25lIjoiMTg1NDk5ODg3MjMiLCJvcGVuSWQiOm51bGwsInV1aWQiOiI0YTgwYTA5Yy03MWE0LTQwZjktODA3Yy00NWJmYjliYmViZDEiLCJlbWFpbCI6IiIsImV4cCI6MTc1NTUxNzM1Mn0.7Ls_xzWyTPhOEQwZIRDVasbZxwjoTxfWxJVhIDLlQvqVfLySXp6R7yY1elAxHbxUUtdWioyYAP2Rck0R69MOmA"
BASE_URL = "https://mineru.net/api/v4"

class MinerUParser:
    """MinerU PDFè§£æå™¨"""
    
    def __init__(self, api_token=API_TOKEN):
        self.api_token = api_token
        self.headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_token}'
        }
    
    def upload_file_with_retry(self, file_path, upload_url, max_retries=3):
        """å¸¦é‡è¯•æœºåˆ¶çš„æ–‡ä»¶ä¸Šä¼ """
        file_size = os.path.getsize(file_path)
        filename = os.path.basename(file_path)
        
        print(f"ğŸ“„ æ–‡ä»¶: {filename}")
        print(f"ğŸ“Š å¤§å°: {file_size / (1024*1024):.2f} MB")
        
        for attempt in range(max_retries):
            print(f"ğŸ”„ å°è¯•ä¸Šä¼  (ç¬¬{attempt + 1}/{max_retries}æ¬¡)...")
            
            try:
                with open(file_path, 'rb') as f:
                    response = requests.put(
                        upload_url,
                        data=f,
                        timeout=(30, 300)  # è¿æ¥30ç§’ï¼Œè¯»å–300ç§’
                    )
                
                if response.status_code == 200:
                    print(f"âœ… {filename} ä¸Šä¼ æˆåŠŸ!")
                    return True
                else:
                    print(f"âŒ ä¸Šä¼ å¤±è´¥ - çŠ¶æ€ç : {response.status_code}")
                    
            except requests.exceptions.Timeout:
                print(f"â±ï¸ ä¸Šä¼ è¶…æ—¶ (å°è¯• {attempt + 1})")
            except Exception as e:
                print(f"âŒ ä¸Šä¼ é”™è¯¯: {e}")
            
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 10
                print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
        
        print(f"âŒ {filename} ä¸Šä¼ å¤±è´¥")
        return False
    
    def parse_single_pdf(self, pdf_file):
        """è§£æå•ä¸ªPDFæ–‡ä»¶"""
        if not os.path.exists(pdf_file):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pdf_file}")
            return None
        
        file_size = os.path.getsize(pdf_file)
        if file_size > 200 * 1024 * 1024:  # 200MBé™åˆ¶
            print(f"âŒ æ–‡ä»¶å¤§å° {file_size/(1024*1024):.1f}MB è¶…è¿‡200MBé™åˆ¶")
            return None
        
        print(f"ğŸš€ å¼€å§‹è§£æå•ä¸ªPDFæ–‡ä»¶")
        print("=" * 60)
        
        # æ­¥éª¤1: ç”³è¯·ä¸Šä¼ é“¾æ¥
        print("æ­¥éª¤1: ç”³è¯·ä¸Šä¼ é“¾æ¥")
        url = f'{BASE_URL}/file-urls/batch'
        
        data = {
            "enable_formula": True,
            "language": "ch",
            "enable_table": True,
            "model_version": "v2",
            "files": [{
                "name": os.path.basename(pdf_file),
                "is_ocr": True,
                "data_id": f"single_{int(time.time())}"
            }]
        }
        
        try:
            response = requests.post(url, headers=self.headers, json=data, timeout=30)
            
            if response.status_code != 200 or response.json()["code"] != 0:
                print(f"âŒ ç”³è¯·ä¸Šä¼ é“¾æ¥å¤±è´¥")
                return None
            
            result = response.json()
            batch_id = result["data"]["batch_id"]
            upload_url = result["data"]["file_urls"][0]
            
            print(f"âœ… è·å–ä¸Šä¼ é“¾æ¥æˆåŠŸ")
            print(f"ğŸ“‹ æ‰¹æ¬¡ID: {batch_id}")
            
        except Exception as e:
            print(f"âŒ ç”³è¯·ä¸Šä¼ é“¾æ¥å‡ºé”™: {e}")
            return None
        
        # æ­¥éª¤2: ä¸Šä¼ æ–‡ä»¶
        print("\næ­¥éª¤2: ä¸Šä¼ æ–‡ä»¶")
        if not self.upload_file_with_retry(pdf_file, upload_url):
            return None
        
        # æ­¥éª¤3: ç­‰å¾…è§£æ
        print("\næ­¥éª¤3: ç­‰å¾…è§£æå®Œæˆ")
        return self.wait_for_result(batch_id)
    
    def parse_batch_pdfs(self, pdf_files):
        """æ‰¹é‡è§£æPDFæ–‡ä»¶"""
        valid_files = []
        for pdf_file in pdf_files:
            if os.path.exists(pdf_file):
                file_size = os.path.getsize(pdf_file)
                if file_size <= 200 * 1024 * 1024:  # 200MBé™åˆ¶
                    valid_files.append(pdf_file)
                else:
                    print(f"âš ï¸ è·³è¿‡å¤§æ–‡ä»¶: {pdf_file} ({file_size/(1024*1024):.1f}MB)")
            else:
                print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {pdf_file}")
        
        if not valid_files:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„PDFæ–‡ä»¶å¯ä»¥å¤„ç†")
            return None
        
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡è§£æ {len(valid_files)} ä¸ªPDFæ–‡ä»¶")
        print("=" * 60)
        
        # æ­¥éª¤1: ç”³è¯·æ‰¹é‡ä¸Šä¼ é“¾æ¥
        print("æ­¥éª¤1: ç”³è¯·æ‰¹é‡ä¸Šä¼ é“¾æ¥")
        url = f'{BASE_URL}/file-urls/batch'
        
        files_data = []
        for i, pdf_file in enumerate(valid_files):
            files_data.append({
                "name": os.path.basename(pdf_file),
                "is_ocr": True,
                "data_id": f"batch_{i}_{int(time.time())}"
            })
        
        data = {
            "enable_formula": True,
            "language": "ch",
            "enable_table": True,
            "model_version": "v2",
            "files": files_data
        }
        
        try:
            response = requests.post(url, headers=self.headers, json=data, timeout=30)
            
            if response.status_code != 200 or response.json()["code"] != 0:
                print(f"âŒ ç”³è¯·æ‰¹é‡ä¸Šä¼ é“¾æ¥å¤±è´¥")
                return None
            
            result = response.json()
            batch_id = result["data"]["batch_id"]
            upload_urls = result["data"]["file_urls"]
            
            print(f"âœ… è·å–æ‰¹é‡ä¸Šä¼ é“¾æ¥æˆåŠŸ")
            print(f"ğŸ“‹ æ‰¹æ¬¡ID: {batch_id}")
            
        except Exception as e:
            print(f"âŒ ç”³è¯·æ‰¹é‡ä¸Šä¼ é“¾æ¥å‡ºé”™: {e}")
            return None
        
        # æ­¥éª¤2: æ‰¹é‡ä¸Šä¼ æ–‡ä»¶
        print("\næ­¥éª¤2: æ‰¹é‡ä¸Šä¼ æ–‡ä»¶")
        upload_success = 0
        for pdf_file, upload_url in zip(valid_files, upload_urls):
            if self.upload_file_with_retry(pdf_file, upload_url):
                upload_success += 1
            print()  # ç©ºè¡Œåˆ†éš”
        
        print(f"ğŸ“Š ä¸Šä¼ ç»“æœ: {upload_success}/{len(valid_files)} ä¸ªæ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
        
        if upload_success == 0:
            print("âŒ æ²¡æœ‰æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
            return None
        
        # æ­¥éª¤3: ç­‰å¾…æ‰¹é‡è§£æ
        print("\næ­¥éª¤3: ç­‰å¾…æ‰¹é‡è§£æå®Œæˆ")
        return self.wait_for_batch_result(batch_id)
    
    def wait_for_result(self, batch_id, max_wait=2400):
        """ç­‰å¾…å•ä¸ªæ–‡ä»¶è§£æç»“æœ"""
        url = f'{BASE_URL}/extract-results/batch/{batch_id}'
        start_time = time.time()
        
        while time.time() - start_time < max_wait:
            try:
                response = requests.get(url, headers=self.headers, timeout=30)
                
                if response.status_code == 200:
                    result = response.json()
                    if result['code'] == 0:
                        extract_results = result['data']['extract_result']
                        if extract_results:
                            file_result = extract_results[0]
                            state = file_result['state']
                            
                            elapsed = int(time.time() - start_time)
                            
                            if state == 'done':
                                print(f"[{elapsed}s] ğŸ‰ è§£æå®Œæˆ!")
                                return file_result
                            elif state == 'failed':
                                error_msg = file_result.get('err_msg', 'æœªçŸ¥é”™è¯¯')
                                print(f"[{elapsed}s] âŒ è§£æå¤±è´¥: {error_msg}")
                                return None
                            elif state == 'running':
                                progress = file_result.get('extract_progress', {})
                                if progress:
                                    extracted = progress.get('extracted_pages', 0)
                                    total = progress.get('total_pages', 0)
                                    print(f"[{elapsed}s] ğŸ“Š è§£æè¿›åº¦: {extracted}/{total} é¡µ")
                                else:
                                    print(f"[{elapsed}s] ğŸ”„ æ­£åœ¨è§£æ...")
                            else:
                                print(f"[{elapsed}s] â³ çŠ¶æ€: {state}")
                
            except Exception as e:
                elapsed = int(time.time() - start_time)
                print(f"[{elapsed}s] âŒ æŸ¥è¯¢å‡ºé”™: {e}")
            
            time.sleep(10)
        
        print("âŒ ç­‰å¾…è¶…æ—¶")
        return None
    
    def wait_for_batch_result(self, batch_id, max_wait=3600):
        """ç­‰å¾…æ‰¹é‡è§£æç»“æœ"""
        url = f'{BASE_URL}/extract-results/batch/{batch_id}'
        start_time = time.time()
        
        print(f"ğŸ“‹ æ‰¹æ¬¡ID: {batch_id}")
        
        while time.time() - start_time < max_wait:
            try:
                response = requests.get(url, headers=self.headers, timeout=30)
                
                if response.status_code == 200:
                    result = response.json()
                    if result['code'] == 0:
                        extract_results = result['data']['extract_result']
                        if extract_results:
                            elapsed = int(time.time() - start_time)
                            
                            # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶çŠ¶æ€
                            all_done = True
                            done_count = 0
                            failed_count = 0
                            
                            for file_result in extract_results:
                                state = file_result['state']
                                if state == 'done':
                                    done_count += 1
                                elif state == 'failed':
                                    failed_count += 1
                                elif state not in ['done', 'failed']:
                                    all_done = False
                            
                            total_files = len(extract_results)
                            print(f"[{elapsed}s] ğŸ“Š è¿›åº¦: {done_count}âœ… {failed_count}âŒ / {total_files} æ–‡ä»¶")
                            
                            if all_done:
                                print(f"[{elapsed}s] ğŸ‰ æ‰¹é‡è§£æå®Œæˆ!")
                                return extract_results
                
            except Exception as e:
                elapsed = int(time.time() - start_time)
                print(f"[{elapsed}s] âŒ æŸ¥è¯¢å‡ºé”™: {e}")
            
            time.sleep(15)
        
        print("âŒ æ‰¹é‡ç­‰å¾…è¶…æ—¶")
        return None
    
    def download_result(self, result_data, output_dir="parsed_results"):
        """ä¸‹è½½å•ä¸ªè§£æç»“æœ"""
        if 'full_zip_url' not in result_data:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä¸‹è½½é“¾æ¥")
            return None
        
        zip_url = result_data['full_zip_url']
        filename = result_data.get('file_name', 'result')
        
        print(f"ğŸ“¥ ä¸‹è½½è§£æç»“æœ: {filename}")
        
        try:
            os.makedirs(output_dir, exist_ok=True)
            
            # ä¸‹è½½ZIP
            response = requests.get(zip_url, timeout=300, stream=True)
            if response.status_code != 200:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {response.status_code}")
                return None
            
            # ä¿å­˜å’Œè§£å‹
            timestamp = int(time.time())
            safe_name = "".join(c for c in filename if c.isalnum() or c in (' ', '-', '_', '.')).strip()
            extract_dir = os.path.join(output_dir, f"{safe_name}_{timestamp}")
            os.makedirs(extract_dir, exist_ok=True)
            
            zip_path = os.path.join(output_dir, f"temp_{timestamp}.zip")
            with open(zip_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            # è§£å‹
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)
            
            os.remove(zip_path)  # åˆ é™¤ä¸´æ—¶ZIPæ–‡ä»¶
            
            print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {extract_dir}")
            self.show_result_summary(extract_dir)
            
            return extract_dir
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤„ç†å‡ºé”™: {e}")
            return None
    
    def download_batch_results(self, results_list, output_dir="batch_parsed_results"):
        """ä¸‹è½½æ‰¹é‡è§£æç»“æœ"""
        if not results_list:
            print("âŒ æ²¡æœ‰è§£æç»“æœ")
            return []
        
        os.makedirs(output_dir, exist_ok=True)
        downloaded_dirs = []
        
        print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ {len(results_list)} ä¸ªæ–‡ä»¶çš„è§£æç»“æœ")
        
        for i, file_result in enumerate(results_list, 1):
            if file_result['state'] != 'done' or 'full_zip_url' not in file_result:
                filename = file_result.get('file_name', f'æ–‡ä»¶{i}')
                print(f"â­ï¸ [{i}] è·³è¿‡ {filename}: çŠ¶æ€ {file_result['state']}")
                continue
            
            print(f"ğŸ“¥ [{i}] ä¸‹è½½: {file_result.get('file_name', f'æ–‡ä»¶{i}')}")
            result_dir = self.download_result(file_result, output_dir)
            if result_dir:
                downloaded_dirs.append(result_dir)
        
        print(f"ğŸŠ æ‰¹é‡ä¸‹è½½å®Œæˆ! æˆåŠŸä¸‹è½½: {len(downloaded_dirs)} ä¸ªæ–‡ä»¶")
        return downloaded_dirs
    
    def show_result_summary(self, extract_dir):
        """æ˜¾ç¤ºè§£æç»“æœæ‘˜è¦"""
        # æŸ¥æ‰¾å¹¶æ˜¾ç¤ºä¸»è¦æ–‡ä»¶
        md_files = list(Path(extract_dir).glob('*.md'))
        if md_files:
            md_file = md_files[0]
            print(f"ğŸ“„ Markdownæ–‡ä»¶: {md_file.name}")
            
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    lines = content.split('\n')
                    print(f"ğŸ“Š æ€»è¡Œæ•°: {len(lines)}")
                    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {len(content):,} å­—ç¬¦")
                    
                    # æ˜¾ç¤ºå‰å‡ è¡Œ
                    print("\nğŸ“– å†…å®¹é¢„è§ˆ:")
                    print("-" * 40)
                    for i, line in enumerate(lines[:5], 1):
                        if line.strip():
                            print(f"{i:2d}| {line[:80]}{'...' if len(line) > 80 else ''}")
                    if len(lines) > 5:
                        print(f"   | ... (è¿˜æœ‰{len(lines)-5}è¡Œ)")
                    print("-" * 40)
                    
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = MinerUParser()
    
    print("=" * 80)
    print("ğŸ” MinerU PDFè§£æå·¥å…·")
    print("=" * 80)
    
    # è·å–å‘½ä»¤è¡Œå‚æ•°
    mode = sys.argv[1] if len(sys.argv) > 1 else "auto"
    
    # æŸ¥æ‰¾å½“å‰ç›®å½•çš„PDFæ–‡ä»¶
    pdf_files = list(Path('.').glob('*.pdf'))
    
    if not pdf_files:
        print("âŒ å½“å‰ç›®å½•æ²¡æœ‰æ‰¾åˆ°PDFæ–‡ä»¶")
        return
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶:")
    for i, pdf_file in enumerate(pdf_files, 1):
        size = os.path.getsize(pdf_file) / (1024*1024)
        print(f"  {i}. {pdf_file.name} ({size:.1f} MB)")
    
    print("\n" + "=" * 80)
    
    if mode == "single" or (mode == "auto" and len(pdf_files) == 1):
        # å•ä¸ªæ–‡ä»¶æ¨¡å¼
        if len(pdf_files) == 1:
            selected_file = pdf_files[0]
        else:
            try:
                choice = int(input(f"è¯·é€‰æ‹©è¦è§£æçš„æ–‡ä»¶ (1-{len(pdf_files)}): ")) - 1
                if 0 <= choice < len(pdf_files):
                    selected_file = pdf_files[choice]
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©")
                    return
            except (ValueError, KeyboardInterrupt):
                print("âŒ è¾“å…¥æ— æ•ˆæˆ–ç”¨æˆ·å–æ¶ˆ")
                return
        
        print(f"ğŸ“„ é€‰æ‹©æ–‡ä»¶: {selected_file.name}")
        
        # è§£æå•ä¸ªæ–‡ä»¶
        result = parser.parse_single_pdf(str(selected_file))
        
        if result:
            print("\n" + "=" * 80)
            print("ğŸ“¥ ä¸‹è½½è§£æç»“æœ")
            extract_dir = parser.download_result(result)
            if extract_dir:
                print(f"\nğŸ‰ è§£æå®Œæˆ! ç»“æœä¿å­˜åœ¨: {extract_dir}")
        else:
            print("\nâŒ è§£æå¤±è´¥")
    
    elif mode == "batch" or (mode == "auto" and len(pdf_files) > 1):
        # æ‰¹é‡æ–‡ä»¶æ¨¡å¼
        if mode == "auto":
            confirm = input(f"å‘ç°å¤šä¸ªPDFæ–‡ä»¶ï¼Œæ˜¯å¦æ‰¹é‡è§£æ? (y/N): ").strip().lower()
            if confirm != 'y':
                print("âŒ ç”¨æˆ·å–æ¶ˆ")
                return
        
        # æ‰¹é‡è§£æ
        results = parser.parse_batch_pdfs([str(f) for f in pdf_files])
        
        if results:
            print("\n" + "=" * 80)
            print("ğŸ“¥ æ‰¹é‡ä¸‹è½½è§£æç»“æœ")
            downloaded_dirs = parser.download_batch_results(results)
            if downloaded_dirs:
                print(f"\nğŸ‰ æ‰¹é‡è§£æå®Œæˆ! ç»“æœä¿å­˜åœ¨:")
                for i, dir_path in enumerate(downloaded_dirs, 1):
                    print(f"  {i}. {dir_path}")
        else:
            print("\nâŒ æ‰¹é‡è§£æå¤±è´¥")
    
    else:
        print("âŒ æ— æ•ˆçš„æ¨¡å¼å‚æ•°")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python mineru_pdf_parser.py single   # å•ä¸ªæ–‡ä»¶è§£æ")
        print("  python mineru_pdf_parser.py batch    # æ‰¹é‡æ–‡ä»¶è§£æ")
        print("  python mineru_pdf_parser.py          # è‡ªåŠ¨æ£€æµ‹æ¨¡å¼")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()